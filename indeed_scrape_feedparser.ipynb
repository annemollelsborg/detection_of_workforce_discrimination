{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a30cd2d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m jobs\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_nurse_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     df   \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     69\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnurse_jobs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mscrape_nurse_jobs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mscrape_nurse_jobs\u001b[39m():\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sync_playwright() \u001b[38;5;28;01mas\u001b[39;00m pw:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# 1) launch a visible browser (so Cloudflare sees ‚Äúreal‚Äù Chrome)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         browser \u001b[38;5;241m=\u001b[39m pw\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mlaunch(headless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m         ctx     \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mnew_context(user_agent\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppleWebKit/537.36 (KHTML, like Gecko) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChrome/112.0.0.0 Safari/537.36\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m         ))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/playwright/sync_api/_context_manager.py:47\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_own_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 47\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Error(\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mPlease use the Async API instead.\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m# block while waiting for a response.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgreenlet_main\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mError\u001b[0m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "from playwright.sync_api import sync_playwright\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_nurse_jobs():\n",
    "    with sync_playwright() as pw:\n",
    "        # 1) launch a visible browser (so Cloudflare sees ‚Äúreal‚Äù Chrome)\n",
    "        browser = pw.chromium.launch(headless=False)\n",
    "        ctx     = browser.new_context(user_agent=(\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/112.0.0.0 Safari/537.36\"\n",
    "        ))\n",
    "        page    = ctx.new_page()\n",
    "\n",
    "        # 2) go to the search page and accept cookies\n",
    "        url = \"https://www.indeed.com/jobs?q=nurse&l=United+States\"\n",
    "        page.goto(url, timeout=30000)\n",
    "        try:\n",
    "            page.click(\"#onetrust-accept-btn-handler\", timeout=5000)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 3) infinite-scroll a few times\n",
    "        for _ in range(4):\n",
    "            page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        # 4) grab all the job cards\n",
    "        cards = page.locator(\"div.job_seen_beacon\")\n",
    "        count = cards.count()\n",
    "        print(f\"üëç Loaded {count} cards on the page\")\n",
    "\n",
    "        # 5) extract previews + full description\n",
    "        jobs = []\n",
    "        for i in range(min(count, 30)):\n",
    "            card = cards.nth(i)\n",
    "            link = card.locator(\"a\").get_attribute(\"href\")\n",
    "            title   = card.locator(\"h2.jobTitle span\").inner_text()\n",
    "            company = card.locator(\"span.companyName\").inner_text()\n",
    "            loc     = card.locator(\"div.companyLocation\").inner_text()\n",
    "            summary = card.locator(\"div.job-snippet\").inner_text()\n",
    "\n",
    "            # open detail in a new tab\n",
    "            detail = ctx.new_page()\n",
    "            detail.goto(link, timeout=30000)\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                desc = detail.locator(\"#jobDescriptionText\").inner_text()\n",
    "            except:\n",
    "                desc = \"\"\n",
    "            detail.close()\n",
    "\n",
    "            jobs.append({\n",
    "                \"title\":       title,\n",
    "                \"company\":     company,\n",
    "                \"location\":    loc,\n",
    "                \"summary\":     summary,\n",
    "                \"link\":        link,\n",
    "                \"description\": desc\n",
    "            })\n",
    "\n",
    "        browser.close()\n",
    "        return jobs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_nurse_jobs()\n",
    "    df   = pd.DataFrame(data)\n",
    "    df.to_csv(\"nurse_jobs.csv\", index=False)\n",
    "    print(\"‚úÖ Done ‚Äî scraped\", len(df), \"jobs.\")\n",
    "    print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
